{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from itertools import repeat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Utils import custom_data_loader, preprocess_data\n",
    "from Utils.SummaryWriter import LogSummary\n",
    "from Models.simpleFFBNN import SimpleFFBNN\n",
    "from Models.denseRegression import DenseRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  False\n",
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    \"\"\"Function to get the device to be used for training the model\n",
    "    \"\"\"\n",
    "    cuda = torch.cuda.is_available()\n",
    "    print(\"CUDA Available: \", cuda)\n",
    "\n",
    "    if cuda:\n",
    "        gpu = GPUtil.getFirstAvailable()\n",
    "        print(\"GPU Available: \", gpu)\n",
    "        torch.cuda.set_device(gpu)\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print(\"Device: \", device)\n",
    "    return device\n",
    "\n",
    "device = get_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristian/Documents/Skole/9. Semester/Thesis Preparation/Code/BNNs/Utils/config.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.X['savings'] = np.where(self.X['savings'] == 'low', 0, np.where(self.X['savings'] == 'medium', 1, 2))\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataloader_train, dataloader_test, dataloader_val = preprocess_data(pd.read_csv('/Users/kristian/Documents/Skole/9. Semester/Thesis Preparation/Code/BNNs/Data/quality_of_food.csv'), batch_size = 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleFFBNN(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('/Users/kristian/Documents/Skole/9. Semester/Thesis Preparation/Code/BNNs/trainedModels/simple_model.pth', map_location=torch.device('cpu'))\n",
    "#print(checkpoint)\n",
    "#model.load_state_dict(checkpoint['model'])\n",
    "model.load_state_dict(checkpoint)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Saveoutput():\n",
    "    def __init__(self, instances, batch_size, rounds):\n",
    "        self.T = instances\n",
    "        self.batch_size = batch_size\n",
    "        self.outputs = []\n",
    "        self.rounds = rounds\n",
    "        self.counter = 0\n",
    "\n",
    "\n",
    "    def __call__(self, module, module_in, module_out):\n",
    "        if self.counter < 3:\n",
    "            sample_data = np.random.randint(self.batch_size)\n",
    "            outs = module_out.view(self.batch_size, -1)\n",
    "            #outs = module_out.view(self.T, self.batch_size, -1)[:, 0, :]\n",
    "            layer_size = outs.shape[1]\n",
    "\n",
    "            \n",
    "            write_summary.per_round_layer_output(layer_size, outs, self.rounds)\n",
    "\n",
    "            self.counter += 1\n",
    "\n",
    "\n",
    "    def clear(self):\n",
    "        self.outputs = []\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_summary = LogSummary(name = 'Simple Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Model:SimpleFFBNN(\n",
      "  (fc1): KlLayers (4 -> 10)\n",
      "  (fc2): KlLayers (10 -> 20)\n",
      "  (fc3): KlLayers (20 -> 1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class runActiveLearning():\n",
    "    def __init__(self, model_name, model, dataloader_train, dataloader_test, dataloader_val, epochs, rounds, learning_rate, batch_size, instances, highest_unc, seed_sample, retrain, resume_round):\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self.dataloader_train = dataloader_train\n",
    "        self.dataloader_test = dataloader_test\n",
    "        self.dataloader_val = dataloader_val\n",
    "        self.epochs = epochs\n",
    "        self.rounds = rounds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.instances = instances\n",
    "        self.highest_unc = highest_unc\n",
    "        self.seed_sample = seed_sample\n",
    "\n",
    "\n",
    "        # a set of lists to store the selected indices with highest uncertainty\n",
    "        self.highest_unc = set([])\n",
    "        # unexplored data\n",
    "        self.unexplored_data = set(range(len(dataloader_train.dataset)))\n",
    "\n",
    "        if resume_round and not retrain:\n",
    "            self.InitModel(load_weigths=True, res_round=resume_round)\n",
    "        elif resume_round and retrain:\n",
    "            self.InitModel(load_weigths=False, res_round=resume_round)\n",
    "        else:\n",
    "            self.InitModel()\n",
    "\n",
    "\n",
    "        training_params = sum(p.numel() for p in self.model.parameters())\n",
    "        print('Running Model:{}'.format(model, training_params, self.epochs, self.batch_size))\n",
    "\n",
    "\n",
    "    def InitModel(self,load_weigths = False, res_round = None):\n",
    "        if self.model_name == 'simple':\n",
    "            self.model = SimpleFFBNN(4, 1, )\n",
    "        else:\n",
    "            self.model = DenseRegressor(4, 1)\n",
    "            \n",
    "    def loadSeedModel(self):\n",
    "        # load the trained model\n",
    "        model = SimpleFFBNN(4, 1)\n",
    "        checkpoint = torch.load('Activelearning/SeedModels/simple_model_best.pth', map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint)\n",
    "        self.model = model\n",
    "        print(f'Model loaded: {model}')\n",
    "\n",
    "    def loadPreTrainedModel(self, load_weigths, res_round):\n",
    "        self.getTrainedModel(res_round)\n",
    "        # load weights\n",
    "        if DEVICE.type == 'cpu':\n",
    "            state = torch.load(self.train_weight_path, map_location=torch.device('cpu'))\n",
    "        else:\n",
    "            state = torch.load(self.train_weight_path)\n",
    "\n",
    "        self.highest_unc = state['highest_unc']\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        if load_weigths:\n",
    "            self.model.load_state_dict(state['weights'])\n",
    "            self.optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "    def getEntropy(self, y):\n",
    "        ensemble_probabilities = y.mean(0)\n",
    "       # print(f'Ensemble probabilities func: {ensemble_probabilities.shape}')\n",
    "        entropy = Categorical(probs = ensemble_probabilities).entropy()\n",
    "        # get the entropy of the ensemble probabilities\n",
    "        #entropy = -torch.sum(ensemble_probabilities * torch.log(ensemble_probabilities), dim=1)\n",
    "\n",
    "        #probabilities = Categorical(probs = ensemble_probabilities)\n",
    "\n",
    "       # print(f'Probabilities func: {probabilities.probs[0:5]}')\n",
    "\n",
    "        #entropy = probabilities.entropy()\n",
    "\n",
    "        #entropy  = -torch.sum(ensemble_probabilities * torch.log(ensemble_probabilities), dim=1)\n",
    "\n",
    "        #print(f'Entropy func: {entropy[0:5]}')\n",
    "        return entropy\n",
    "\n",
    "\n",
    "    def trainSeedModelClosedForm(self, rounds):\n",
    "        # loss function\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "\n",
    "        if rounds == 1:\n",
    "            self.highest_unc = set(range(self.seed_sample))\n",
    "            self.unexplored_data = self.unexplored.difference(self.highest_unc)\n",
    "\n",
    "\n",
    "\n",
    "        uncertainty = []\n",
    "        hook_handles = []\n",
    "        save_output = Saveoutput(instances= self.instances, batch_size=self.batch_size, rounds = self.rounds)\n",
    "        self.model.eval()\n",
    "        for layer in self.model.kl_layers:\n",
    "            hook_handles.append(layer.register_forward_hook(save_output))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_index, (X, y) in enumerate(self.dataloader_train):\n",
    "                batch_size = X.shape[0]\n",
    "                #print(f'X before repeat: {X}')\n",
    "               # print(f'y before repeat: {y}')\n",
    "                save_output.batch_size = batch_size\n",
    "                X = X.repeat(self.instances, 1)\n",
    "                #print(f'X after repeat: {X}, {X.shape}')\n",
    "                \n",
    "\n",
    "                y = y.squeeze()\n",
    "                # squeeze the y to remove the extra dimension\n",
    "                \n",
    "                y = y.repeat(self.instances)\n",
    "        \n",
    "                X, y = X.to(device), y.to(device)\n",
    "                y_pred = model(X)\n",
    "                print(f'y_pred: {y_pred.shape}, {y_pred[0:5]}, {y_pred[128:133]}')\n",
    "                \n",
    "                \n",
    "\n",
    "                ensemble_outputs = y.reshape(self.instances, batch_size, 1) # reshape to instances x batch_size x 1 (output size)\n",
    "                \n",
    "                \n",
    "                uncertainty.append(self.getEntropy(ensemble_outputs))\n",
    "                   \n",
    "        \n",
    "            save_output.clear()\n",
    "            save_output.counter = 0\n",
    "            for handle in hook_handles:\n",
    "                handle.remove()\n",
    "            \n",
    "            uncertainty = torch.cat(uncertainty)\n",
    "            \n",
    "            new_indices = torch.argsort(uncertainty, descending=True).tolist()\n",
    "\n",
    "            # remove already selected data\n",
    "            new_indices = [i for i in new_indices if i not in self.highest_unc]  \n",
    "\n",
    "            # select the highest uncertainty data\n",
    "            self.highest_unc.union(set(new_indices[:self.seed_sample]))\n",
    "            print(f'higheset_unc: {self.highest_unc}')\n",
    "            self.unexplored_data = self.unexplored_data.difference(self.highest_unc)\n",
    "\n",
    "    \n",
    "    def objective(self, output, target, kl, beta):\n",
    "        loss_fun = nn.MSELoss()\n",
    "        discrimination_error = loss_fun(output.view(-1), target.view(-1))\n",
    "        variational_bound = discrimination_error + beta * kl\n",
    "        return variational_bound, discrimination_error, kl\n",
    "\n",
    "\n",
    "    def getTrainedModel(self, res_round):\n",
    "        retrain = self.retrain\n",
    "        self.train_weight_path = f'Activelearning/SeedModels/simple_model_best.pth'\n",
    "        if res_round:\n",
    "            self.train_weight_path = f'Activelearning/SeedModels/simple_model_best.pth'\n",
    "        else:\n",
    "            self.train_weight_path = f'Activelearning/SeedModels/simple_model_best.pth'\n",
    "\n",
    "        return (self.model, self.train_weight_path)\n",
    "\n",
    "\n",
    "\n",
    "    def trainModel(self, rounds, epochs):\n",
    "        t_total, v_total = 0, 0\n",
    "        t_r2_scores, v_r2_scores = [], []\n",
    "        self.model.train()\n",
    "        t_loss, v_loss = [], []\n",
    "        t_likelihood, v_likelihood = [], []\n",
    "        t_kl, v_kl = [], []\n",
    "        self.model.train()\n",
    "        m = len(self.dataloader_train)\n",
    "\n",
    "        for batch_index, (inputs, targets) in enumerate(self.dataloader_train):\n",
    "            X = inputs.repeat(1, 1)  # (number of mcmc samples)\n",
    "            Y = targets.repeat(1)\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            outputs = self.model(X)\n",
    "            loss, log_likelihood, kl = self.objective(outputs, Y, self.model.kl_divergence, m)\n",
    "        \n",
    "        t_total += target.size(0)\n",
    "        t_r2_scores.append(r2_score(outputs.detach().cpu()[:,0], targets.numpy()))\n",
    "        t_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for layer in self.model.kl_layers:\n",
    "            layer.clip_variances()\n",
    "\n",
    "        \n",
    "        # validate\n",
    "        m_val = len(self.dataloader_val)\n",
    "        self.model.eval()\n",
    "        for batch_index, (inputs, targets) in enumerate(self.dataloader_val):\n",
    "            X = self.model(inputs)\n",
    "            loss_val, log_likelihood_val, kl_val = self.objective(outputs, Y, self.model.kl_divergence, m_val)\n",
    "        \n",
    "            v_total += target.size(0)\n",
    "            v_loss.append(loss_val.item())\n",
    "            v_likelihood.append(log_likelihood_val.item())\n",
    "            v_kl.append(kl_val.item())\n",
    "           # v_r2_scores.append(r2_score(outputs.detach().cpu()[:,0], targets.numpy()))\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "   # write_summary = LogSummary(name='Simple Model')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# use the class to run the active learning\n",
    "active_learning = runActiveLearning(model_name='simple', model=model, dataloader_train=dataloader_train, dataloader_test=dataloader_test, dataloader_val=dataloader_val, epochs=100, rounds=2, learning_rate=0.001, batch_size=128, instances=3, highest_unc=6, seed_sample=4, retrain=False, resume_round=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred: torch.Size([384, 1]), tensor([[ 0.3558],\n",
      "        [ 0.2122],\n",
      "        [-0.8390],\n",
      "        [ 0.2063],\n",
      "        [ 0.1837]]), tensor([[ 0.3558],\n",
      "        [ 0.2122],\n",
      "        [-0.8390],\n",
      "        [ 0.2063],\n",
      "        [ 0.1837]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.1449],\n",
      "        [-0.9519],\n",
      "        [-1.5050],\n",
      "        [-0.1934],\n",
      "        [ 0.0758]]), tensor([[-0.1449],\n",
      "        [-0.9519],\n",
      "        [-1.5050],\n",
      "        [-0.1934],\n",
      "        [ 0.0758]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.3341],\n",
      "        [-1.1289],\n",
      "        [-0.8976],\n",
      "        [ 0.7849],\n",
      "        [ 0.3607]]), tensor([[-0.3341],\n",
      "        [-1.1289],\n",
      "        [-0.8976],\n",
      "        [ 0.7849],\n",
      "        [ 0.3607]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.2712],\n",
      "        [ 0.7198],\n",
      "        [ 0.6477],\n",
      "        [-0.4300],\n",
      "        [ 0.0229]]), tensor([[ 0.2712],\n",
      "        [ 0.7198],\n",
      "        [ 0.6477],\n",
      "        [-0.4300],\n",
      "        [ 0.0229]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.4118],\n",
      "        [-0.1848],\n",
      "        [ 0.4311],\n",
      "        [-1.1234],\n",
      "        [ 0.3049]]), tensor([[-0.4118],\n",
      "        [-0.1848],\n",
      "        [ 0.4311],\n",
      "        [-1.1234],\n",
      "        [ 0.3049]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.4708],\n",
      "        [-0.2437],\n",
      "        [-0.1208],\n",
      "        [ 0.0766],\n",
      "        [-0.1884]]), tensor([[-0.4708],\n",
      "        [-0.2437],\n",
      "        [-0.1208],\n",
      "        [ 0.0766],\n",
      "        [-0.1884]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 2.6937e-01],\n",
      "        [-1.4754e+00],\n",
      "        [ 4.9090e-04],\n",
      "        [ 2.7565e-02],\n",
      "        [-4.8647e-01]]), tensor([[ 2.6937e-01],\n",
      "        [-1.4754e+00],\n",
      "        [ 4.9090e-04],\n",
      "        [ 2.7565e-02],\n",
      "        [-4.8647e-01]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.8058],\n",
      "        [-0.6786],\n",
      "        [-0.0785],\n",
      "        [-0.1266],\n",
      "        [-0.8572]]), tensor([[ 0.8058],\n",
      "        [-0.6786],\n",
      "        [-0.0785],\n",
      "        [-0.1266],\n",
      "        [-0.8572]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[0.6589],\n",
      "        [0.0759],\n",
      "        [0.1203],\n",
      "        [0.6361],\n",
      "        [0.4233]]), tensor([[0.6589],\n",
      "        [0.0759],\n",
      "        [0.1203],\n",
      "        [0.6361],\n",
      "        [0.4233]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.4922],\n",
      "        [ 1.1949],\n",
      "        [ 0.5527],\n",
      "        [-0.2143],\n",
      "        [ 0.2792]]), tensor([[-0.4922],\n",
      "        [ 1.1949],\n",
      "        [ 0.5527],\n",
      "        [-0.2143],\n",
      "        [ 0.2792]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.5729],\n",
      "        [ 0.3204],\n",
      "        [-0.0982],\n",
      "        [-0.3782],\n",
      "        [ 0.6298]]), tensor([[ 0.5729],\n",
      "        [ 0.3204],\n",
      "        [-0.0982],\n",
      "        [-0.3782],\n",
      "        [ 0.6298]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.1676],\n",
      "        [ 0.4509],\n",
      "        [-1.3909],\n",
      "        [-0.0457],\n",
      "        [ 0.6026]]), tensor([[ 0.1676],\n",
      "        [ 0.4509],\n",
      "        [-1.3909],\n",
      "        [-0.0457],\n",
      "        [ 0.6026]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.1307],\n",
      "        [ 0.2315],\n",
      "        [ 0.8253],\n",
      "        [-0.1407],\n",
      "        [ 0.7762]]), tensor([[-0.1307],\n",
      "        [ 0.2315],\n",
      "        [ 0.8253],\n",
      "        [-0.1407],\n",
      "        [ 0.7762]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.4637],\n",
      "        [ 0.4404],\n",
      "        [-0.0832],\n",
      "        [-0.7641],\n",
      "        [ 0.4444]]), tensor([[-0.4637],\n",
      "        [ 0.4404],\n",
      "        [-0.0832],\n",
      "        [-0.7641],\n",
      "        [ 0.4444]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.2811],\n",
      "        [ 0.3347],\n",
      "        [ 0.4534],\n",
      "        [-0.4290],\n",
      "        [ 0.6015]]), tensor([[ 0.2811],\n",
      "        [ 0.3347],\n",
      "        [ 0.4534],\n",
      "        [-0.4290],\n",
      "        [ 0.6015]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.8056],\n",
      "        [ 0.7290],\n",
      "        [-0.9729],\n",
      "        [ 0.3315],\n",
      "        [-0.1893]]), tensor([[-0.8056],\n",
      "        [ 0.7290],\n",
      "        [-0.9729],\n",
      "        [ 0.3315],\n",
      "        [-0.1893]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.5457],\n",
      "        [ 0.4857],\n",
      "        [-0.3286],\n",
      "        [-0.2674],\n",
      "        [-0.7833]]), tensor([[-0.5457],\n",
      "        [ 0.4857],\n",
      "        [-0.3286],\n",
      "        [-0.2674],\n",
      "        [-0.7833]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.4927],\n",
      "        [ 0.4015],\n",
      "        [ 0.1004],\n",
      "        [-0.0059],\n",
      "        [ 0.0473]]), tensor([[-0.4927],\n",
      "        [ 0.4015],\n",
      "        [ 0.1004],\n",
      "        [-0.0059],\n",
      "        [ 0.0473]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.3297],\n",
      "        [ 0.1124],\n",
      "        [-1.2738],\n",
      "        [-0.7054],\n",
      "        [ 0.9573]]), tensor([[ 0.3297],\n",
      "        [ 0.1124],\n",
      "        [-1.2738],\n",
      "        [-0.7054],\n",
      "        [ 0.9573]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.2431],\n",
      "        [-1.5302],\n",
      "        [ 0.1668],\n",
      "        [ 0.4465],\n",
      "        [-0.3883]]), tensor([[ 0.2431],\n",
      "        [-1.5302],\n",
      "        [ 0.1668],\n",
      "        [ 0.4465],\n",
      "        [-0.3883]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-1.2130],\n",
      "        [ 0.4853],\n",
      "        [ 0.1861],\n",
      "        [-1.2296],\n",
      "        [ 0.5751]]), tensor([[-1.2130],\n",
      "        [ 0.4853],\n",
      "        [ 0.1861],\n",
      "        [-1.2296],\n",
      "        [ 0.5751]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.5798],\n",
      "        [ 0.0868],\n",
      "        [-0.3406],\n",
      "        [ 0.4725],\n",
      "        [-0.9710]]), tensor([[-0.5798],\n",
      "        [ 0.0868],\n",
      "        [-0.3406],\n",
      "        [ 0.4725],\n",
      "        [-0.9710]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.4667],\n",
      "        [ 0.7686],\n",
      "        [-0.1382],\n",
      "        [ 0.7325],\n",
      "        [ 0.3228]]), tensor([[ 0.4667],\n",
      "        [ 0.7686],\n",
      "        [-0.1382],\n",
      "        [ 0.7325],\n",
      "        [ 0.3228]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.7637],\n",
      "        [-0.2369],\n",
      "        [-1.3939],\n",
      "        [ 0.3819],\n",
      "        [ 0.4422]]), tensor([[-0.7637],\n",
      "        [-0.2369],\n",
      "        [-1.3939],\n",
      "        [ 0.3819],\n",
      "        [ 0.4422]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.2693],\n",
      "        [-0.9335],\n",
      "        [ 0.1747],\n",
      "        [ 0.3833],\n",
      "        [-0.0931]]), tensor([[-0.2693],\n",
      "        [-0.9335],\n",
      "        [ 0.1747],\n",
      "        [ 0.3833],\n",
      "        [-0.0931]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.6805],\n",
      "        [-0.1095],\n",
      "        [ 0.5754],\n",
      "        [-0.9123],\n",
      "        [-0.1367]]), tensor([[-0.6805],\n",
      "        [-0.1095],\n",
      "        [ 0.5754],\n",
      "        [-0.9123],\n",
      "        [-0.1367]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.2933],\n",
      "        [ 0.2431],\n",
      "        [-0.5071],\n",
      "        [-0.3827],\n",
      "        [-0.4695]]), tensor([[ 0.2933],\n",
      "        [ 0.2431],\n",
      "        [-0.5071],\n",
      "        [-0.3827],\n",
      "        [-0.4695]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[0.5275],\n",
      "        [0.1521],\n",
      "        [0.2302],\n",
      "        [0.1606],\n",
      "        [0.3387]]), tensor([[0.5275],\n",
      "        [0.1521],\n",
      "        [0.2302],\n",
      "        [0.1606],\n",
      "        [0.3387]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.1891],\n",
      "        [ 0.4074],\n",
      "        [ 0.0910],\n",
      "        [-0.5743],\n",
      "        [-0.6733]]), tensor([[ 0.1891],\n",
      "        [ 0.4074],\n",
      "        [ 0.0910],\n",
      "        [-0.5743],\n",
      "        [-0.6733]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.2291],\n",
      "        [-0.2220],\n",
      "        [ 1.0067],\n",
      "        [ 0.4548],\n",
      "        [ 0.2436]]), tensor([[ 0.2291],\n",
      "        [-0.2220],\n",
      "        [ 1.0067],\n",
      "        [ 0.4548],\n",
      "        [ 0.2436]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.6399],\n",
      "        [ 0.5337],\n",
      "        [-1.5279],\n",
      "        [-0.3413],\n",
      "        [ 0.6539]]), tensor([[ 0.6399],\n",
      "        [ 0.5337],\n",
      "        [-1.5279],\n",
      "        [-0.3413],\n",
      "        [ 0.6539]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.8596],\n",
      "        [-0.4673],\n",
      "        [-1.3398],\n",
      "        [ 0.4832],\n",
      "        [ 0.7201]]), tensor([[-0.8596],\n",
      "        [-0.4673],\n",
      "        [-1.3398],\n",
      "        [ 0.4832],\n",
      "        [ 0.7201]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-1.0005],\n",
      "        [-0.0531],\n",
      "        [ 0.4765],\n",
      "        [-0.3050],\n",
      "        [ 0.1033]]), tensor([[-1.0005],\n",
      "        [-0.0531],\n",
      "        [ 0.4765],\n",
      "        [-0.3050],\n",
      "        [ 0.1033]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.3899],\n",
      "        [-1.5395],\n",
      "        [ 0.2311],\n",
      "        [-0.0823],\n",
      "        [ 0.1294]]), tensor([[-0.3899],\n",
      "        [-1.5395],\n",
      "        [ 0.2311],\n",
      "        [-0.0823],\n",
      "        [ 0.1294]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.4877],\n",
      "        [ 0.3346],\n",
      "        [ 0.1848],\n",
      "        [-0.9563],\n",
      "        [ 0.3327]]), tensor([[ 0.4877],\n",
      "        [ 0.3346],\n",
      "        [ 0.1848],\n",
      "        [-0.9563],\n",
      "        [ 0.3327]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.4884],\n",
      "        [ 0.2671],\n",
      "        [-0.7424],\n",
      "        [-0.1799],\n",
      "        [ 0.0211]]), tensor([[ 0.4884],\n",
      "        [ 0.2671],\n",
      "        [-0.7424],\n",
      "        [-0.1799],\n",
      "        [ 0.0211]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.3687],\n",
      "        [-0.5371],\n",
      "        [ 0.5864],\n",
      "        [ 0.2156],\n",
      "        [ 0.0819]]), tensor([[ 0.3687],\n",
      "        [-0.5371],\n",
      "        [ 0.5864],\n",
      "        [ 0.2156],\n",
      "        [ 0.0819]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.7406],\n",
      "        [ 0.4104],\n",
      "        [ 0.6619],\n",
      "        [ 0.5378],\n",
      "        [ 0.6802]]), tensor([[-0.7406],\n",
      "        [ 0.4104],\n",
      "        [ 0.6619],\n",
      "        [ 0.5378],\n",
      "        [ 0.6802]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.9979],\n",
      "        [-0.1290],\n",
      "        [ 0.4193],\n",
      "        [ 0.2562],\n",
      "        [-0.4791]]), tensor([[ 0.9979],\n",
      "        [-0.1290],\n",
      "        [ 0.4193],\n",
      "        [ 0.2562],\n",
      "        [-0.4791]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.2844],\n",
      "        [-0.8214],\n",
      "        [ 0.1351],\n",
      "        [ 0.1680],\n",
      "        [-0.7137]]), tensor([[ 0.2844],\n",
      "        [-0.8214],\n",
      "        [ 0.1351],\n",
      "        [ 0.1680],\n",
      "        [-0.7137]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.5069],\n",
      "        [ 0.1301],\n",
      "        [ 0.2568],\n",
      "        [-0.1713],\n",
      "        [ 0.2918]]), tensor([[ 0.5069],\n",
      "        [ 0.1301],\n",
      "        [ 0.2568],\n",
      "        [-0.1713],\n",
      "        [ 0.2918]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.9077],\n",
      "        [ 0.7229],\n",
      "        [ 0.1145],\n",
      "        [ 0.2825],\n",
      "        [-0.9204]]), tensor([[-0.9077],\n",
      "        [ 0.7229],\n",
      "        [ 0.1145],\n",
      "        [ 0.2825],\n",
      "        [-0.9204]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.1072],\n",
      "        [ 0.1821],\n",
      "        [ 0.0367],\n",
      "        [-0.8908],\n",
      "        [-0.5082]]), tensor([[-0.1072],\n",
      "        [ 0.1821],\n",
      "        [ 0.0367],\n",
      "        [-0.8908],\n",
      "        [-0.5082]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.3299],\n",
      "        [ 0.6929],\n",
      "        [-0.0345],\n",
      "        [ 0.2610],\n",
      "        [ 0.2760]]), tensor([[ 0.3299],\n",
      "        [ 0.6929],\n",
      "        [-0.0345],\n",
      "        [ 0.2610],\n",
      "        [ 0.2760]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-1.0592],\n",
      "        [ 0.7475],\n",
      "        [ 0.0047],\n",
      "        [ 0.5124],\n",
      "        [-0.1744]]), tensor([[-1.0592],\n",
      "        [ 0.7475],\n",
      "        [ 0.0047],\n",
      "        [ 0.5124],\n",
      "        [-0.1744]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.1200],\n",
      "        [ 0.0254],\n",
      "        [-1.0392],\n",
      "        [ 0.6138],\n",
      "        [ 0.6297]]), tensor([[ 0.1200],\n",
      "        [ 0.0254],\n",
      "        [-1.0392],\n",
      "        [ 0.6138],\n",
      "        [ 0.6297]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.3060],\n",
      "        [ 0.1605],\n",
      "        [-0.1234],\n",
      "        [ 0.6402],\n",
      "        [ 0.3640]]), tensor([[ 0.3060],\n",
      "        [ 0.1605],\n",
      "        [-0.1234],\n",
      "        [ 0.6402],\n",
      "        [ 0.3640]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.6278],\n",
      "        [ 0.3326],\n",
      "        [-0.1466],\n",
      "        [-0.5664],\n",
      "        [ 0.1091]]), tensor([[ 0.6278],\n",
      "        [ 0.3326],\n",
      "        [-0.1466],\n",
      "        [-0.5664],\n",
      "        [ 0.1091]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.2937],\n",
      "        [ 0.8147],\n",
      "        [ 0.1023],\n",
      "        [ 0.1957],\n",
      "        [-1.0411]]), tensor([[-0.2937],\n",
      "        [ 0.8147],\n",
      "        [ 0.1023],\n",
      "        [ 0.1957],\n",
      "        [-1.0411]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[0.1336],\n",
      "        [0.2431],\n",
      "        [0.1933],\n",
      "        [0.4561],\n",
      "        [0.1257]]), tensor([[0.1336],\n",
      "        [0.2431],\n",
      "        [0.1933],\n",
      "        [0.4561],\n",
      "        [0.1257]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[-0.2000],\n",
      "        [-0.2268],\n",
      "        [-0.1591],\n",
      "        [-0.1484],\n",
      "        [-0.9689]]), tensor([[-0.2000],\n",
      "        [-0.2268],\n",
      "        [-0.1591],\n",
      "        [-0.1484],\n",
      "        [-0.9689]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.2467],\n",
      "        [ 0.4491],\n",
      "        [-1.5717],\n",
      "        [-0.3768],\n",
      "        [ 0.7837]]), tensor([[ 0.2467],\n",
      "        [ 0.4491],\n",
      "        [-1.5717],\n",
      "        [-0.3768],\n",
      "        [ 0.7837]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.7324],\n",
      "        [-0.5210],\n",
      "        [ 0.6889],\n",
      "        [ 0.2290],\n",
      "        [ 0.1095]]), tensor([[ 0.7324],\n",
      "        [-0.5210],\n",
      "        [ 0.6889],\n",
      "        [ 0.2290],\n",
      "        [ 0.1095]])\n",
      "y_pred: torch.Size([384, 1]), tensor([[ 0.3438],\n",
      "        [ 0.7558],\n",
      "        [-1.1968],\n",
      "        [ 0.3458],\n",
      "        [-0.1114]]), tensor([[ 0.3438],\n",
      "        [ 0.7558],\n",
      "        [-1.1968],\n",
      "        [ 0.3458],\n",
      "        [-0.1114]])\n",
      "y_pred: torch.Size([264, 1]), tensor([[ 1.1963],\n",
      "        [ 0.3894],\n",
      "        [ 0.0976],\n",
      "        [-1.2637],\n",
      "        [ 0.1411]]), tensor([[ 0.4667],\n",
      "        [-0.3147],\n",
      "        [ 0.3332],\n",
      "        [ 0.2855],\n",
      "        [-0.2797]])\n",
      "higheset_unc: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "active_learning.trainSeedModelClosedForm(rounds = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSeedModelClosedForm(self):\n",
    "    hook_handles = []\n",
    "    save_output = saveOutput(self.instances, self.batch_size, 0)\n",
    "    self.model.eval()\n",
    "    for layer in self.model.layers:\n",
    "        hook_handles.append(layer.register_forward_hook(save_output))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_index, (X, y) in enumerate(self.data_train):\n",
    "            batch_size = X.shape[0]\n",
    "            save_output.batch_size = batch_size\n",
    "            X = X.repeat(self.instances, 1)\n",
    "            y = y.repeat(self.instances)\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            ensemble_outputs = self.model(X)\n",
    "\n",
    "        save_output.clear()\n",
    "        save_output.counter = 0\n",
    "        for handle in hook_handles:\n",
    "            handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
