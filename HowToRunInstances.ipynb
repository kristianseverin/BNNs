{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from itertools import repeat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Utils import custom_data_loader, preprocess_data, preprocess_activeL_data\n",
    "from Utils.SummaryWriter import LogSummary\n",
    "from Models.simpleFFBNN import SimpleFFBNN\n",
    "from Models.denseRegression import DenseRegressor\n",
    "from Models.paperModel import SimpleFFBNNPaper\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available:  False\n",
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    \"\"\"Function to get the device to be used for training the model\n",
    "    \"\"\"\n",
    "    cuda = torch.cuda.is_available()\n",
    "    print(\"CUDA Available: \", cuda)\n",
    "\n",
    "    if cuda:\n",
    "        gpu = GPUtil.getFirstAvailable()\n",
    "        print(\"GPU Available: \", gpu)\n",
    "        torch.cuda.set_device(gpu)\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print(\"Device: \", device)\n",
    "    return device\n",
    "\n",
    "device = get_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "#dataloader_train, dataloader_test, dataloader_val = preprocess_data(pd.read_csv('/Users/kristian/Documents/Skole/9. Semester/Thesis Preparation/Code/BNNs/Data/quality_of_food.csv'), batch_size = 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleFFBNNPaper(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint = torch.load('/Users/kristian/Documents/Skole/9. Semester/Thesis Preparation/Code/BNNs/trainedModels/simple_model.pth', map_location=torch.device('cpu'))\n",
    "#print(checkpoint)\n",
    "#model.load_state_dict(checkpoint['model'])\n",
    "#model.load_state_dict(checkpoint)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOutput():\n",
    "    def __init__(self, instances, batch_size, rounds):\n",
    "        self.T = instances\n",
    "        self.batch_size = batch_size\n",
    "        self.outputs = []\n",
    "        self.rounds = rounds\n",
    "        self.counter = 0\n",
    "\n",
    "\n",
    "    def __call__(self, module, module_in, module_out):\n",
    "        if self.counter < 3:\n",
    "            sample_data = np.random.randint(self.batch_size)\n",
    "            #outs = module_out.view(self.batch_size, -1)\n",
    "            outs = module_out.view(self.T, self.batch_size, -1)[:, 0, :]\n",
    "            layer_size = outs.shape[1]\n",
    "\n",
    "            \n",
    "            write_summary.per_round_layer_output(layer_size, outs, self.rounds)\n",
    "            \n",
    "            # print the output of the layer\n",
    "            \n",
    "            self.counter += 1\n",
    "\n",
    "\n",
    "    def clear(self):\n",
    "        self.outputs = []\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristian/Documents/Skole/9. Semester/Thesis Preparation/Code/BNNs/Utils/config.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.X['savings'] = np.where(self.X['savings'] == 'low', 0, np.where(self.X['savings'] == 'medium', 1, 2))\n"
     ]
    }
   ],
   "source": [
    "dataset_train, dataset_test, dataset_activeL = preprocess_activeL_data(pd.read_csv('/Users/kristian/Documents/Skole/9. Semester/Thesis Preparation/Code/BNNs/Data/quality_of_food.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data using the old function\n",
    "#dataloader_train, dataloader_test, dataloader_val, dataset_train, dataset_test, dataset_val = preprocess_data(pd.read_csv('/Users/kristian/Documents/Skole/9. Semester/Thesis Preparation/Code/BNNs/Data/quality_of_food.csv'), batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class runActiveLearning():\n",
    "    def __init__(self, model_name, model, top_unc, dataloader_train, dataloader_test, dataset_active_l, epochs, rounds, learning_rate, \n",
    "    batch_size, instances, seed_sample, retrain, resume_round, optimizer):\n",
    "        self.model_name = model_name\n",
    "        self.model = model\n",
    "        self.top_unc = top_unc\n",
    "        self.dataloader_train = dataloader_train\n",
    "        self.dataloader_test = dataloader_test\n",
    "        self.dataset_active_l = dataset_active_l\n",
    "        self.epochs = epochs\n",
    "        self.rounds = rounds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.instances = instances\n",
    "        self.seed_sample = seed_sample\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # a set of lists to store the selected indices with highest uncertainty\n",
    "        self.selected_data = set([])\n",
    "        # unexplored data\n",
    "        self.unexplored_data = set(range(len(dataloader_train)))\n",
    "\n",
    "        # make sure sklearn.metrics.r2_score is imported\n",
    "        #self.r2_score = r2_score\n",
    "\n",
    "\n",
    "    \n",
    "    def objective(self, output, target, kl, beta):\n",
    "        '''Objective function to calculate the loss function / KL divergence'''\n",
    "        loss_fun = nn.MSELoss()\n",
    "        discrimination_error = loss_fun(output.view(-1), target)\n",
    "        variational_bound = discrimination_error + beta * kl\n",
    "        return variational_bound, discrimination_error, kl\n",
    "\n",
    "    def get_entropy(self, y):\n",
    "        '''Function to calculate the entropy of the ensemble outputs'''\n",
    "        #print(f'this is the y passed as input to get_entropy: {y.shape}, {y[0:5]}')\n",
    "        ensemble_probabilities = y.mean(1)\n",
    "        #print(f'Ensemble probabilities ent: {ensemble_probabilities.shape}, {ensemble_probabilities[0:5]}')\n",
    "        entropy = Categorical(probs = ensemble_probabilities).entropy()\n",
    "        #print(f'Entropy: {entropy.shape}, {entropy[0:5]}')\n",
    "        return entropy\n",
    "\n",
    "\n",
    "\n",
    "    def get_validation_data(self, is_validation):\n",
    "        if not is_validation:\n",
    "            # train sampler randomly samples data from the selected data set\n",
    "            train_sampler = SubsetRandomSampler(list(self.selected_data))\n",
    "            # train loader will load the data from the train sampler\n",
    "            self.train_loader = DataLoader(self.dataloader_train, batch_size=self.batch_size, sampler=train_sampler, num_workers=1)\n",
    "\n",
    "        indices = list(self.unexplored_data)\n",
    "        np.random.shuffle(indices)\n",
    "        split = int(np.floor(0.1 * len(indices)))  # this line is to split the training_data into 90% training and 10% validation\n",
    "        validation_idx = np.random.choice(indices, size = split) # this line is to randomly select 10% of the data for validation\n",
    "        train_sampler = SubsetRandomSampler(list(self.selected_data))\n",
    "        validation_sampler = SubsetRandomSampler(validation_idx)\n",
    "        self.train_loader = DataLoader(self.dataloader_train, batch_size=self.batch_size, sampler=train_sampler, num_workers=1)\n",
    "        self.validation_loader = DataLoader(self.dataloader_train, batch_size=self.batch_size, sampler=validation_sampler, num_workers=1)\n",
    "\n",
    "    def random_data(self, rounds):\n",
    "        if rounds == 0:    \n",
    "            # randomly select data\n",
    "            self.selected_data = set(range(self.dataloader_train))  # seed sample in Rakeesh & Jain paper\n",
    "            print(f'selected data points first round: {self.selected_data}')\n",
    "            #self.unexplored_data = self.unexplored_data.difference(self.selected_data) # all \n",
    "\n",
    "        else:\n",
    "            minimum_index = np.random.choice(list(self.unexplored_data), self.top_unc)\n",
    "            print(f'minimum index: {minimum_index}')\n",
    "            self.selected_data = self.selected_data.union(minimum_index)\n",
    "            print(f'selected data points second round and onwards: {self.selected_data}')\n",
    "            self.unexplored_data = self.unexplored_data.difference(self.selected_data)\n",
    "            print(f'unexplored data points second round and onwards: {self.unexplored_data}')\n",
    "\n",
    "\n",
    "    def activeDataSelection(self, rounds):\n",
    "        \n",
    "        # for the first round select all the data\n",
    "        if rounds == 1:\n",
    "            # select all the active data as all data should be predicted with uncertainty\n",
    "            self.active_data = dataset_activeL\n",
    "            all_data = DataLoader(self.dataset_active_l, batch_size=self.batch_size, num_workers=1)\n",
    "            correct = 0\n",
    "            metrics = []\n",
    "            hook_handles = []\n",
    "            save_output = SaveOutput(self.instances, self.batch_size, self.rounds)\n",
    "            self.model.eval()\n",
    "            for layer in self.model.kl_layers:\n",
    "                handle = layer.register_forward_hook(save_output)\n",
    "                hook_handles.append(handle)\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch_index, (X, y) in enumerate(all_data):\n",
    "                    batch_size = X.shape[0]\n",
    "                    save_output.batch_size = batch_size\n",
    "                    print(f'x: {X.shape}, y: {y.shape}')\n",
    "                    print(f'x: {X[0:5]}, y: {y[0:5]}')\n",
    "                    X = X.repeat(self.instances, 1)\n",
    "                    y = y.squeeze()\n",
    "                    y = y.repeat(self.instances)\n",
    "                    \n",
    "                    X, y = X.to(device), y.to(device)\n",
    "\n",
    "                    y_pred = self.model(X)\n",
    "                   # print(f'y_pred: {y_pred.shape}, {y_pred[0:5]}')\n",
    "\n",
    "\n",
    "                    ensemble_outputs = y_pred.reshape(self.instances, batch_size, 1)\n",
    "                    print(f'ensemble outputs: {ensemble_outputs.shape}, {ensemble_outputs[0:5]}')\n",
    "                    print(f'ensemble output 1: {ensemble_outputs[0,0,0]}')\n",
    "                    print(f'ensemble output 2: {ensemble_outputs[1,0,0]}')\n",
    "          \n",
    "                    entropy = self.get_entropy(ensemble_outputs)\n",
    "                    #print(f'Entropy: {entropy.shape}, {entropy[0:5]}')\n",
    "                    metrics.append(entropy)\n",
    "\n",
    "                # print the outputs in the last layer from save_output\n",
    "              \n",
    "\n",
    "                save_output.clear()\n",
    "                save_output.counter = 0\n",
    "                for handle in hook_handles:\n",
    "                    handle.remove()\n",
    "\n",
    "                metrics = torch.cat(metrics)\n",
    "                \n",
    "                # print all the uniwue values in the metrics\n",
    "\n",
    "                \n",
    "                new_indices = torch.argsort(metrics, descending=True).tolist()\n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            all_data = DataLoader(self.dataset_active_l, batch_size=self.batch_size, num_workers=1)\n",
    "            correct = 0\n",
    "            metrics = []\n",
    "            hook_handles = []\n",
    "            save_output = SaveOutput(self.instances, self.batch_size, self.rounds)\n",
    "            self.model.eval()\n",
    "            for layer in self.model.kl_layers:\n",
    "                hook_handles.append(layer.register_forward_hook(save_output))\n",
    "\n",
    "            \n",
    "            #print(f'this is the active learnign data: {all_data}, {len(all_data)}')\n",
    "\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_index, (X, y) in enumerate(all_data):\n",
    "                    batch_size = X.shape[0]\n",
    "                    save_output.batch_size = batch_size\n",
    "                    X = X.repeat(self.instances, 1)\n",
    "                    y = y.squeeze()\n",
    "                    #print(f'y: {y.shape}')\n",
    "                    y = y.repeat(self.instances)\n",
    "                    X, y = X.to(device), y.to(device)\n",
    "                    y_pred = self.model(X)\n",
    "                    ensemble_outputs = y.reshape(self.instances, batch_size, 1) # reshape to instances x batch_size x 1 (output size)\n",
    "                    print(f'ensemble outputs: {ensemble_outputs.shape}, {ensemble_outputs[0:5]}')\n",
    "                    print(f'ensemble output 1: {ensemble_outputs[0,0,0]}')\n",
    "                    print(f'ensemble output 2: {ensemble_outputs[1,0,0]}')\n",
    "            \n",
    "                    entropy = self.get_entropy(ensemble_outputs)\n",
    "                    #print(f'Entropy: {entropy.shape}, {entropy[0:5]}')\n",
    "                    metrics.append(entropy)\n",
    "\n",
    "                save_output.clear()\n",
    "                save_output.counter = 0\n",
    "                for handle in hook_handles:\n",
    "                    handle.remove()\n",
    "\n",
    "                metrics = torch.cat(metrics)\n",
    "                new_indices = torch.argsort(metrics, descending=True).tolist()\n",
    "                new_indices = [i for i in new_indices if i not in self.selected_data]\n",
    "                print(f'new indices: {new_indices}')\n",
    "\n",
    "                self.selected_data.union(set(new_indices[:self.top_unc]))\n",
    "                print(f'selected data points: {self.selected_data}')\n",
    "                self.unexplored_data = self.unexplored_data.difference(self.selected_data)\n",
    "\n",
    "    def annotateSelectedData(self, rounds):\n",
    "        if rounds == 1:\n",
    "            # do nothing\n",
    "            pass\n",
    "        #else:\n",
    "            # get the indices of the selected data\n",
    "            #indices = list(self.selected_data)\n",
    "            # get the data from the dataloader\n",
    "            \n",
    "            \n",
    "\n",
    "    def TrainModel(self, rounds, epochs, is_validation):\n",
    "    \n",
    "        \n",
    "        #print('running model')\n",
    "        t_total, v_total = 0, 0\n",
    "        t_r2_scores = []\n",
    "        if epochs == 1:\n",
    "            self.get_validation_data(is_validation)\n",
    "        self.model.train()\n",
    "        t_loss, v_loss = [], []\n",
    "        t_likelihood, v_likelihood = [], []\n",
    "        t_kl, v_kl = [], []\n",
    "        self.model.train()\n",
    "        m = len(self.train_loader)\n",
    "       # print(f'this is the train loader: {self.train_loader}, {len(self.train_loader)}')\n",
    "\n",
    "       # print('before loop, this is the train loader: {}'.format(self.train_loader), len(self.train_loader))\n",
    "        for batch_index, (inputs, targets) in enumerate(self.train_loader):\n",
    "         #   print('running loop')\n",
    "            X = inputs.repeat(1, 1) # (number of mcmc samples, input size)\n",
    "            Y = targets.repeat(1)\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            outputs = self.model(X)\n",
    "            loss, log_likelihood, kl = self.objective(outputs, Y, self.model.kl_divergence(), 1 / m)\n",
    "            t_likelihood.append(log_likelihood.item())\n",
    "            t_kl.append(kl.item())\n",
    "            t_total += targets.size(0)\n",
    "          \n",
    "            # calculate r2 score manually\n",
    "            r2_score_value = 1 - (np.sum((outputs.detach().cpu().numpy() - targets.detach().cpu().numpy()) ** 2) / np.sum((targets.detach().cpu().numpy() - np.mean(targets.detach().cpu().numpy())) ** 2))\n",
    "            t_r2_scores.append(r2_score_value)\n",
    "            \n",
    "            t_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "\n",
    "            # define the optimizer\n",
    "            optimizer = self.optimizer\n",
    "\n",
    "            optimizer.step()\n",
    "            for layer in self.model.kl_layers:\n",
    "                layer.clip_variances()\n",
    "        \n",
    "        if is_validation:\n",
    "            #print(f'this is the validation data {self.validation_loader}, these are the characteristics {len(self.validation_loader)}')\n",
    "            m_val = len(self.validation_loader)\n",
    "            self.model.eval()\n",
    "            for batch_index, (inputs, targets) in enumerate(self.validation_loader):\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss_val, log_likelihood_val, kl_val = self.objective(outputs, targets, self.model.kl_divergence(), 1 / m_val)\n",
    "                v_total += targets.size(0)\n",
    "                v_loss.append(loss_val.item())\n",
    "                v_likelihood.append(log_likelihood_val.item())\n",
    "                v_kl.append(kl_val.item())\n",
    "\n",
    "            \n",
    "            avg_v_loss = np.average(v_loss)\n",
    "            avg_t_loss = np.average(t_loss)\n",
    "            avg_v_likelihood = np.average(v_likelihood)\n",
    "            avg_t_likelihood = np.average(t_likelihood)\n",
    "            avg_v_kl = np.average(v_kl)\n",
    "            avg_t_kl = np.average(t_kl)\n",
    "\n",
    "\n",
    "            print(\n",
    "                'epochs: {}, train loss: {}, train likelihood: {}, train kl: {}'.format(\n",
    "                    epochs, avg_t_loss, \\\n",
    "                    avg_t_likelihood, avg_t_kl))\n",
    "\n",
    "            print(\n",
    "                'epochs: {}, validation loss: {}, validation likelihood: {}, validation kl: {}'.format(\n",
    "                    epochs, avg_v_loss, \\\n",
    "                    avg_v_likelihood, avg_v_kl))\n",
    "\n",
    "            return avg_v_loss\n",
    "\n",
    "        else:\n",
    "            avg_t_loss = np.average(t_loss)\n",
    "            avg_t_likelihood = np.average(t_likelihood)\n",
    "            avg_t_kl = np.average(t_kl)\n",
    "            avg_t_r2 = np.average(t_r2_scores)\n",
    "\n",
    "         #   print(\n",
    "          #      'epochs: {}, train loss: {}, train likelihood: {}, train kl: {}, train_avg_R2: {}'.format(\n",
    "           #         epochs, avg_t_loss, \\\n",
    "            #        avg_t_likelihood, avg_t_kl, avg_t_r2))\n",
    "\n",
    "            return avg_t_loss, avg_t_r2\n",
    "\n",
    "    \n",
    "    def TestModel(self, rounds):\n",
    "        if device.type == 'cpu':\n",
    "            state = torch.load(self.train_weight_path, map_location=torch.device('cpu'))\n",
    "        else:\n",
    "            state = torch.load(self.train_weight_path)\n",
    "\n",
    "        self.model.load_state_dict(state['weights'])\n",
    "        print(f'Model loaded: {self.model}')\n",
    "\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        actual = []\n",
    "        mse_scores = []\n",
    "        with torch.no_grad():\n",
    "            for batch_index, (inputs, targets) in enumerate(self.dataloader_test):\n",
    "                X, Y = inputs.to(device), targets.to(device)\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                # Calculate the MSE loss for the batch\n",
    "                mse_loss = nn.MSELoss()\n",
    "                loss = mse_loss(outputs, Y)\n",
    "\n",
    "                # Get the MSE score as a Python scalar\n",
    "                mse_score = loss.item()\n",
    "                mse_scores.append(mse_score)\n",
    "\n",
    "                # Convert predictions and actual values to numpy arrays\n",
    "                predictions.append(outputs.detach().cpu().numpy())      \n",
    "                actual.append(Y.detach().cpu().numpy())\n",
    "                \n",
    "\n",
    "        predictions = np.concatenate(predictions)\n",
    "        actual = np.concatenate(actual)\n",
    "        df = pd.DataFrame(data = {'Predictions': predictions, 'Actual': actual})\n",
    "        df.loc['R2'] = 1 - np.sum((df.Actual - df.Predictions) ** 2) / np.sum((df.Actual - np.mean(df.Actual)) ** 2)\n",
    "        df.loc['MSE'] = mean_squared_error(df.Actual, df.Predictions)\n",
    "        \n",
    "        #print('Non-Ensemble Test MSE:{:.3f}, TestR2:{:.3f}'.format(df.loc[\"MSE\"][0], df.loc[\"R2\"][0]))\n",
    "                \n",
    "\n",
    "\n",
    "    def getTrainedModel(self, rounds):\n",
    "        # path to save the trained model\n",
    "        self.train_weight_path = 'trainedModels/trained_weights/' + self.model_name + '_' + 'e' + str(self.epochs) + '_' + '-r' + str(rounds) + '-b' + str(self.batch_size) + '.pkl'\n",
    "        return (self.model, self.train_weight_path)\n",
    "\n",
    "\n",
    "    def saveModel(self, model, optimizer, path_to_save):\n",
    "        state = {\n",
    "            'rounds': self.rounds,\n",
    "            'weights': model.state_dict(),\n",
    "            'selected_data': self.selected_data,\n",
    "            'optimizer': self.optimizer.state_dict()\n",
    "            }\n",
    "\n",
    "        path_to_save = 'trainedModels/trained_weights/' + self.model_name + '_' + 'e' + str(self.epochs) + '_' + '-r' + str(self.rounds) + '-b' + str(self.batch_size) + '.pkl'\n",
    "\n",
    "        torch.save(state, path_to_save)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristian/.local/share/virtualenvs/DataViz-TTGQRQcT/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/kristian/.local/share/virtualenvs/DataViz-TTGQRQcT/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([54, 1])) that is different to the input size (torch.Size([54])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 5, train loss: nan, train likelihood: nan, train kl: nan\n",
      "epochs: 5, validation loss: 136.41441802978517, validation likelihood: 1.2199296057224274, validation kl: 1351.94482421875\n",
      "Round: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristian/.local/share/virtualenvs/DataViz-TTGQRQcT/lib/python3.11/site-packages/numpy/lib/function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/Users/kristian/.local/share/virtualenvs/DataViz-TTGQRQcT/lib/python3.11/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[ 0.8127, -0.8946, -1.2525, -0.3387],\n",
      "        [ 1.6392, -0.5597, -1.2525, -0.3387],\n",
      "        [-1.5953, -1.4526, -0.0195, -0.3387],\n",
      "        [-0.5488, -1.0062, -0.0195, -0.3387],\n",
      "        [-0.7723,  0.2216, -1.2525, -0.3387]]), y: tensor([[-0.8543],\n",
      "        [-0.6537],\n",
      "        [ 0.2214],\n",
      "        [ 1.5523],\n",
      "        [-1.8935]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[-0.5384],\n",
      "        [-0.6036],\n",
      "        [-0.0062],\n",
      "        [-0.3466],\n",
      "        [ 0.6493]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[ 1.4592, -1.2294, -1.2525, -0.3387],\n",
      "        [-0.7338,  0.1099, -0.0195, -0.3387],\n",
      "        [-0.9604, -1.0062, -0.0195,  2.9527],\n",
      "        [ 1.0703,  1.3377, -0.0195, -0.3387],\n",
      "        [ 0.1623,  0.2216, -1.2525, -0.3387]]), y: tensor([[ 0.3034],\n",
      "        [-0.2435],\n",
      "        [ 0.9780],\n",
      "        [ 1.1877],\n",
      "        [-0.4532]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[-0.7793],\n",
      "        [-0.1242],\n",
      "        [-0.0289],\n",
      "        [-0.1119],\n",
      "        [ 0.3916]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[ 1.9998e-01,  1.4493e+00, -1.9482e-02, -3.3868e-01],\n",
      "        [-4.2461e-01,  1.1145e+00,  1.2135e+00, -3.3868e-01],\n",
      "        [ 9.9380e-01,  6.6801e-01, -1.9482e-02,  2.9527e+00],\n",
      "        [ 1.2065e+00, -1.6630e-03, -1.2525e+00, -3.3868e-01],\n",
      "        [ 3.1998e-01,  1.5609e+00,  1.2135e+00, -3.3868e-01]]), y: tensor([[ 0.2123],\n",
      "        [-0.2617],\n",
      "        [ 0.6590],\n",
      "        [-0.3894],\n",
      "        [-0.6355]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[ 0.1224],\n",
      "        [-0.3312],\n",
      "        [-0.1410],\n",
      "        [-0.2082],\n",
      "        [-0.1831]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[-0.6211,  1.2261,  1.2135, -0.3387],\n",
      "        [ 1.1980,  0.1099, -1.2525, -0.3387],\n",
      "        [ 1.2242, -1.0062, -1.2525, -0.3387],\n",
      "        [-1.4619, -0.0017, -0.0195, -0.3387],\n",
      "        [ 0.3196,  0.7796,  1.2135, -0.3387]]), y: tensor([[-1.7203],\n",
      "        [ 0.2852],\n",
      "        [-0.8087],\n",
      "        [-2.0940],\n",
      "        [ 1.3609]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[-0.3868],\n",
      "        [-0.1756],\n",
      "        [-0.6774],\n",
      "        [-0.1245],\n",
      "        [-0.3127]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[ 0.1181,  0.1099, -0.0195, -0.3387],\n",
      "        [ 1.1680, -1.0062, -1.2525, -0.3387],\n",
      "        [-0.5634, -1.3410,  1.2135,  2.9527],\n",
      "        [-0.6819,  0.5564, -0.0195, -0.3387],\n",
      "        [-1.4430, -0.5597, -1.2525, -0.3387]]), y: tensor([[-0.6993],\n",
      "        [-1.1733],\n",
      "        [ 0.4037],\n",
      "        [-0.5717],\n",
      "        [-0.9545]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[-0.1713],\n",
      "        [-0.6817],\n",
      "        [-0.0317],\n",
      "        [-0.0533],\n",
      "        [ 0.7771]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[-1.6142e+00,  8.9124e-01,  1.2135e+00, -3.3868e-01],\n",
      "        [ 5.9112e-01, -1.6759e+00,  1.2135e+00,  2.9527e+00],\n",
      "        [-9.5536e-01, -1.1178e+00, -1.2525e+00, -3.3868e-01],\n",
      "        [-3.0000e-01,  1.3377e+00, -1.2525e+00, -3.3868e-01],\n",
      "        [ 1.4611e+00, -1.6630e-03,  1.2135e+00, -3.3868e-01]]), y: tensor([[-0.3164],\n",
      "        [ 0.6225],\n",
      "        [ 1.5523],\n",
      "        [ 0.9780],\n",
      "        [ 1.1877]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[-0.4869],\n",
      "        [-0.0560],\n",
      "        [ 0.4974],\n",
      "        [ 0.6568],\n",
      "        [-0.8606]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[ 1.1746,  1.2261, -1.2525, -0.3387],\n",
      "        [-1.3284,  1.5609, -0.0195, -0.3387],\n",
      "        [-1.1873, -0.7830, -1.2525, -0.3387],\n",
      "        [ 0.0458,  1.6725, -0.0195, -0.3387],\n",
      "        [ 0.8138, -0.5597,  1.2135, -0.3387]]), y: tensor([[-0.6537],\n",
      "        [-0.8543],\n",
      "        [-1.1460],\n",
      "        [ 1.1694],\n",
      "        [ 1.2150]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[ 0.4468],\n",
      "        [ 0.0634],\n",
      "        [ 0.6846],\n",
      "        [ 0.2728],\n",
      "        [-0.7007]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[-0.0769,  1.2261, -0.0195,  2.9527],\n",
      "        [-1.3219, -1.1178,  1.2135, -0.3387],\n",
      "        [-0.4561,  0.5564, -1.2525, -0.3387],\n",
      "        [-0.4527,  1.6725,  1.2135, -0.3387],\n",
      "        [ 0.9865,  0.5564, -0.0195, -0.3387]]), y: tensor([[ 0.2943],\n",
      "        [-0.9454],\n",
      "        [-0.3347],\n",
      "        [ 0.3399],\n",
      "        [-0.5170]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[ 0.0208],\n",
      "        [-0.3145],\n",
      "        [ 0.5942],\n",
      "        [-0.0951],\n",
      "        [-0.4873]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[ 0.5515,  0.6680, -1.2525, -0.3387],\n",
      "        [-1.2603, -0.1133,  1.2135, -0.3387],\n",
      "        [-0.9184,  1.2261,  1.2135, -0.3387],\n",
      "        [-1.6388,  1.6725, -1.2525, -0.3387],\n",
      "        [-0.8573,  0.8912,  1.2135, -0.3387]]), y: tensor([[-1.7112],\n",
      "        [ 0.0391],\n",
      "        [ 0.3308],\n",
      "        [-2.0940],\n",
      "        [ 0.2214]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[ 0.4642],\n",
      "        [-0.3657],\n",
      "        [-0.3019],\n",
      "        [ 0.6919],\n",
      "        [-0.4073]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[-0.5754, -0.2249, -0.0195,  2.9527],\n",
      "        [-1.2615,  0.6680,  1.2135, -0.3387],\n",
      "        [ 1.3557, -0.3365, -0.0195,  2.9527],\n",
      "        [-1.6599, -0.8946, -0.0195, -0.3387],\n",
      "        [-0.1527, -1.5642, -1.2525, -0.3387]]), y: tensor([[-0.6537],\n",
      "        [ 0.4493],\n",
      "        [ 1.5523],\n",
      "        [-1.0639],\n",
      "        [-0.2617]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[-0.0262],\n",
      "        [-0.5110],\n",
      "        [-0.0469],\n",
      "        [-0.0586],\n",
      "        [ 0.0934]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[-1.7307,  1.2261, -0.0195,  2.9527],\n",
      "        [ 0.6657,  0.3332, -1.2525, -0.3387],\n",
      "        [-0.3454,  1.5609, -1.2525, -0.3387],\n",
      "        [ 1.0446, -0.4481, -1.2525, -0.3387],\n",
      "        [-0.1665,  1.2261,  1.2135, -0.3387]]), y: tensor([[-0.4623],\n",
      "        [-0.2162],\n",
      "        [ 0.2305],\n",
      "        [ 0.0482],\n",
      "        [ 0.4858]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[ 0.0220],\n",
      "        [ 0.1666],\n",
      "        [ 0.7037],\n",
      "        [-0.3555],\n",
      "        [-0.1938]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[ 0.1204, -1.4526, -1.2525, -0.3387],\n",
      "        [-0.2346,  1.2261, -0.0195, -0.3387],\n",
      "        [ 0.2750, -1.5642, -1.2525,  2.9527],\n",
      "        [ 1.3865,  0.5564,  1.2135, -0.3387],\n",
      "        [-0.9973,  0.5564, -1.2525, -0.3387]]), y: tensor([[ 1.5523],\n",
      "        [-2.0940],\n",
      "        [ 0.8048],\n",
      "        [ 0.8777],\n",
      "        [-1.3921]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[-0.0936],\n",
      "        [ 0.2537],\n",
      "        [-0.1560],\n",
      "        [-0.8609],\n",
      "        [ 0.6661]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[-0.7665, -1.3410, -0.0195, -0.3387],\n",
      "        [-0.5554,  1.2261,  1.2135, -0.3387],\n",
      "        [-1.4434, -1.4526, -1.2525, -0.3387],\n",
      "        [ 0.2315, -0.2249, -1.2525, -0.3387],\n",
      "        [ 0.2131,  1.0029, -1.2525, -0.3387]]), y: tensor([[-0.7175],\n",
      "        [ 0.2487],\n",
      "        [-0.7722],\n",
      "        [ 0.6407],\n",
      "        [-1.7476]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[-0.3360],\n",
      "        [-0.2846],\n",
      "        [ 0.6369],\n",
      "        [ 0.0949],\n",
      "        [ 0.6539]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[-0.1781,  1.3377, -0.0195, -0.3387],\n",
      "        [-1.6265,  0.8912, -1.2525, -0.3387],\n",
      "        [-0.0269, -1.4526, -1.2525, -0.3387],\n",
      "        [-0.0235,  0.5564, -1.2525, -0.3387],\n",
      "        [-1.5761,  0.2216,  1.2135, -0.3387]]), y: tensor([[ 0.8048],\n",
      "        [-2.0940],\n",
      "        [-0.1797],\n",
      "        [ 0.6407],\n",
      "        [-1.2371]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[ 0.3241],\n",
      "        [ 0.7533],\n",
      "        [-0.0547],\n",
      "        [ 0.5110],\n",
      "        [-0.4175]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([64, 4]), y: torch.Size([64, 1])\n",
      "x: tensor([[ 1.6603, -1.2294, -0.0195,  2.9527],\n",
      "        [-1.2050,  1.3377, -1.2525,  2.9527],\n",
      "        [ 1.1026,  1.6725, -1.2525, -0.3387],\n",
      "        [ 1.0353, -0.6713, -0.0195, -0.3387],\n",
      "        [ 0.4304, -0.6713,  1.2135, -0.3387]]), y: tensor([[ 0.9962],\n",
      "        [-1.1824],\n",
      "        [-0.5535],\n",
      "        [ 0.6498],\n",
      "        [ 0.5860]])\n",
      "y_pred: torch.Size([448, 1]), tensor([[-0.2702],\n",
      "        [ 0.0590],\n",
      "        [ 0.4347],\n",
      "        [-0.6524],\n",
      "        [-0.6564]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n",
      "x: torch.Size([40, 4]), y: torch.Size([40, 1])\n",
      "x: tensor([[ 1.2822, -0.8946,  1.2135, -0.3387],\n",
      "        [ 1.2969, -1.2294,  1.2135, -0.3387],\n",
      "        [-1.3123,  0.8912,  1.2135, -0.3387],\n",
      "        [ 1.4895,  1.5609, -1.2525, -0.3387],\n",
      "        [ 0.8911, -0.8946,  1.2135, -0.3387]]), y: tensor([[0.6498],\n",
      "        [1.5523],\n",
      "        [0.8413],\n",
      "        [0.5131],\n",
      "        [1.0236]])\n",
      "y_pred: torch.Size([280, 1]), tensor([[-0.9799],\n",
      "        [-0.9659],\n",
      "        [-0.5031],\n",
      "        [ 0.3391],\n",
      "        [-0.8617]])\n",
      "Entropy: torch.Size([7]), tensor([1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07, 1.1921e-07])\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('trainedModels/trained_weights'):\n",
    "    os.makedirs('trainedModels/trained_weights')\n",
    "\n",
    "\n",
    "# use the class to run the active learning\n",
    "active_learning = runActiveLearning(model_name='simple', model=model, dataloader_train=dataset_train, top_unc = 5, dataloader_test=dataset_test, dataset_active_l= dataset_activeL, epochs=10, rounds=2, learning_rate=0.001, batch_size=64, instances=7, seed_sample=4, retrain=False, resume_round=False, optimizer= torch.optim.Adam(model.parameters(), lr=0.001))\n",
    "\n",
    "write_summary = LogSummary('active_learning')\n",
    "\n",
    "# get data to train the model\n",
    "active_learning.get_validation_data(is_validation=True)\n",
    "\n",
    "# train just the seed model\n",
    "active_learning.TrainModel(1, 5, True)\n",
    "\n",
    "for r in range(1, active_learning.rounds):\n",
    "    print(f'Round: {r}')\n",
    "    active = active_learning.activeDataSelection(r)\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
